#!/usr/bin/env python3
"""
Script de prueba para verificar la configuraci√≥n de Baseten.
Ejecutar antes de iniciar el servidor para validar las credenciales.
"""

import os
import sys
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

def test_baseten_connection():
    """Probar conexi√≥n a Baseten con el modelo Kimi-K2.5"""
    
    print("üß™ Probando configuraci√≥n de Baseten...")
    print()
    
    # Verificar variables de entorno
    baseten_key = os.getenv("BASETEN_API_KEY")
    openai_key = os.getenv("OPENAI_API_KEY")
    
    print("1Ô∏è‚É£ Verificando variables de entorno:")
    print(f"   BASETEN_API_KEY: {'‚úÖ Configurada' if baseten_key else '‚ùå No encontrada'}")
    print(f"   OPENAI_API_KEY: {'‚úÖ Configurada' if openai_key else '‚ùå No encontrada'}")
    print()
    
    if not baseten_key:
        print("‚ùå ERROR: BASETEN_API_KEY no est√° configurada.")
        print("   Crea un archivo .env con: BASETEN_API_KEY=tu-api-key")
        return False
    
    if not openai_key:
        print("‚ùå ERROR: OPENAI_API_KEY no est√° configurada.")
        print("   Crea un archivo .env con: OPENAI_API_KEY=sk-tu-api-key")
        return False
    
    # Probar conexi√≥n a Baseten
    print("2Ô∏è‚É£ Probando conexi√≥n a Baseten...")
    try:
        from openai import OpenAI
        
        client = OpenAI(
            api_key=baseten_key,
            base_url="https://inference.baseten.co/v1"
        )
        
        response = client.chat.completions.create(
            model="moonshotai/Kimi-K2.5",
            messages=[{"role": "user", "content": "Hola, responde con 'Conexi√≥n exitosa'"}],
            temperature=0.0,
            max_tokens=50
        )
        
        result = response.choices[0].message.content
        print(f"   ‚úÖ Conexi√≥n exitosa!")
        print(f"   üì® Respuesta: {result}")
        print()
        
    except Exception as e:
        print(f"   ‚ùå Error de conexi√≥n: {e}")
        print()
        return False
    
    # Probar importaci√≥n de llama-index
    print("3Ô∏è‚É£ Verificando dependencias de llama-index...")
    try:
        from llama_index.core import Settings
        from llama_index.embeddings.openai import OpenAIEmbedding
        print("   ‚úÖ llama-index importado correctamente")
        print()
    except ImportError as e:
        print(f"   ‚ùå Error importando llama-index: {e}")
        print("   Ejecuta: pip install llama-index>=0.10.0")
        return False
    
    # Probar importaci√≥n de BasetenLLM
    print("4Ô∏è‚É£ Verificando clase BasetenLLM...")
    try:
        from interpretador_refactored import BasetenLLM
        print("   ‚úÖ BasetenLLM importado correctamente")
        print()
    except ImportError as e:
        print(f"   ‚ùå Error importando BasetenLLM: {e}")
        return False
    
    print("=" * 60)
    print("‚úÖ TODAS LAS PRUEBAS PASARON")
    print("=" * 60)
    print()
    print("El sistema est√° listo para usar Baseten con Kimi-K2.5!")
    print("Inicia el servidor con: python app.py")
    
    return True


if __name__ == "__main__":
    success = test_baseten_connection()
    sys.exit(0 if success else 1)
